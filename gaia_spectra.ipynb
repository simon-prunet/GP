{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "#from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "#from sklearn import preprocessing\n",
    "import george\n",
    "from george import gp\n",
    "from astropy.io import fits as pyfits\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0c091",
   "metadata": {},
   "source": [
    "# Investigating spectral inter/extrapolation on synthetic stellar spectra with Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(datadir='/Users/prunet/Dropbox/Work/Gaia/', scale_data=True):\n",
    "    \n",
    "    # Get parameter values Teff, log(g), [M/H], [alpha/Fe]\n",
    "    Xtrain = np.loadtxt(datadir+'RVS2020_Grid4.Param',usecols=(1,2,3,4))\n",
    "    n_samples_train = Xtrain.shape[0]\n",
    "    \n",
    "    # Get corresponding spectra, check that dimensions are compatible\n",
    "    Ytrain = pyfits.getdata(datadir+'RVS2020_Grid4_LR.fits').T\n",
    "    n_samples_spec = Ytrain.shape[0]\n",
    "    \n",
    "    if (n_samples_train != n_samples_spec):\n",
    "        print('Incompatible dimensions between parameters list size (%d) and number of spectra (%d)'\n",
    "              %(n_samples_train,n_samples_spec))\n",
    "    if not scale_data:\n",
    "        return Xtrain, Ytrain\n",
    "    else:\n",
    "        scaler = preprocessing.RobustScaler().fit(Xtrain)\n",
    "        Xtrain_scaled = scaler.transform(Xtrain)\n",
    "        return Xtrain_scaled, Ytrain, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d756f9ff",
   "metadata": {},
   "source": [
    "## Get data, scale input features, compute scalar training toy model (norm of spectra, for a start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Ytrain,scaler = get_training_data(scale_data=True)\n",
    "ytrain_power = np.linalg.norm(Ytrain,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488ab49",
   "metadata": {},
   "source": [
    "## Now create GaussianProcessRegressor instance. Train it on data. Use RBF kernel, hyperparameters (amplitude, length scale) will be adjusted during training by minimizing the marginal likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d9d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "## USE HOLDR fast solver of gp here... + explicit marginal likelihood maximisation\n",
    "\n",
    "kernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0))\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=0)\n",
    "gpr.fit(Xtrain,ytrain_power)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xtrain[:,2],Xtrain[:,3],c=np.linalg.norm(Ytrain,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd7a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
